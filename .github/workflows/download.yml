name: Download PubChem Data

on:
  # Manual trigger
  workflow_dispatch:
  
  # Automatic trigger - runs every 6 hours
  schedule:
    - cron: '0 */6 * * *'

jobs:
  download:
    runs-on: ubuntu-latest
    timeout-minutes: 350  # Just under 6 hour GitHub limit
    
    steps:
    # 1. Checkout repository
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    # 2. Set up Python
    - uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    # 3. Install dependencies
    - name: Install requirements
      run: |
        pip install requests
    
    # 4. Download previous data artifact (if exists)
    - name: Download previous data
      uses: actions/download-artifact@v3
      with:
        name: pubchem-data
        path: ./
      continue-on-error: true
    
    # 5. Run the downloader
    - name: Download PubChem compounds
      run: python download_pubchem.py
    
    # 6. Upload data as artifact
    - name: Upload data
      uses: actions/upload-artifact@v3
      with:
        name: pubchem-data
        path: |
          pubchem_downloads/
          progress.json
        retention-days: 90
    
    # 7. Commit progress file (optional - for tracking)
    - name: Commit progress
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add progress.json
        git diff --quiet && git diff --staged --quiet || git commit -m "Update progress: $(date)"
        git push
      continue-on-error: true